{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorlayer as tl\n",
    "import numpy as np\n",
    "import os, time, model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Augmentation\n",
    "Data augmentation used to enrich original data from Brats2017. The augmentation implement to each data is below:\n",
    "1. Flip (left right)\n",
    "2. Elastic Tranform\n",
    "3. Rotate\n",
    "4. Shift\n",
    "5. Shear\n",
    "6. Zoom\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distort_imgs(data):\n",
    "    \"\"\" data augumentation \"\"\"\n",
    "    x1, x2, x3, x4, y = data\n",
    "    # x1, x2, x3, x4, y = tl.prepro.flip_axis_multi([x1, x2, x3, x4, y],  # previous without this, hard-dice=83.7\n",
    "    #                         axis=0, is_random=True) # up down\n",
    "    x1, x2, x3, x4, y = tl.prepro.flip_axis_multi([x1, x2, x3, x4, y],\n",
    "                            axis=1, is_random=True) # left right\n",
    "    x1, x2, x3, x4, y = tl.prepro.elastic_transform_multi([x1, x2, x3, x4, y],\n",
    "                            alpha=720, sigma=24, is_random=True)\n",
    "    x1, x2, x3, x4, y = tl.prepro.rotation_multi([x1, x2, x3, x4, y], rg=20,\n",
    "                            is_random=True, fill_mode='constant') # nearest, constant\n",
    "    x1, x2, x3, x4, y = tl.prepro.shift_multi([x1, x2, x3, x4, y], wrg=0.10,\n",
    "                            hrg=0.10, is_random=True, fill_mode='constant')\n",
    "    x1, x2, x3, x4, y = tl.prepro.shear_multi([x1, x2, x3, x4, y], 0.05,\n",
    "                            is_random=True, fill_mode='constant')\n",
    "    x1, x2, x3, x4, y = tl.prepro.zoom_multi([x1, x2, x3, x4, y],\n",
    "                            zoom_range=[0.9, 1.1], is_random=True,\n",
    "                            fill_mode='constant')\n",
    "    return x1, x2, x3, x4, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vis_imgs(X, y, path, show=False):\n",
    "    \"\"\" show one slice \"\"\"\n",
    "    if y.ndim == 2:\n",
    "        y = y[:,:,np.newaxis]\n",
    "    assert X.ndim == 3\n",
    "    tl.visualize.save_images(np.asarray([X[:,:,0,np.newaxis],\n",
    "        X[:,:,1,np.newaxis], X[:,:,2,np.newaxis],\n",
    "        X[:,:,3,np.newaxis], y]), size=(1, 5),\n",
    "        image_path=path)\n",
    "    if(show):\n",
    "        tl.visualize.read_image(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vis_imgs2(X, y_, y, path, show=False):\n",
    "    \"\"\" show one slice with target \"\"\"\n",
    "    if y.ndim == 2:\n",
    "        y = y[:,:,np.newaxis]\n",
    "    if y_.ndim == 2:\n",
    "        y_ = y_[:,:,np.newaxis]\n",
    "    assert X.ndim == 3\n",
    "    tl.visualize.save_images(np.asarray([X[:,:,0,np.newaxis],\n",
    "        X[:,:,1,np.newaxis], X[:,:,2,np.newaxis],\n",
    "        X[:,:,3,np.newaxis], y_, y]), size=(1, 6),\n",
    "        image_path=path)\n",
    "    if(show):\n",
    "        tl.visualize.read_image(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create folder to save trained model and result images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] checkpoint exists ...\n",
      "[!] samples/all exists ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task = \"all\"\n",
    "save_dir = \"checkpoint\"\n",
    "tl.files.exists_or_mkdir(save_dir)\n",
    "tl.files.exists_or_mkdir(\"samples/{}\".format(task))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOAD DATA\n",
    "Data from Brats2017 and loaded from prepare_data_with_valid.py\n",
    "Data importing from Brats2017 refers to DATA_SIZE define in prepate_data_with_valid which is (\"all\", \"half\", \"small\")\n",
    "1. X_train_input: contain the training data from 4 types MRI scan (flair, t1, t1-c and t2)\n",
    "2. X_train_target: contain the training data from segmentation of tumors\n",
    "3. X_dev_input: containing the validation data from 4 types MRI scan\n",
    "4. x_dev_target: containing the validation data from segementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 163/163 [00:00<00:00, 90708.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survival Data Count 163\n",
      "Data training used for HGG: 100 and LGG: 30\n",
      "Survival patient for HGG: 79 and LGG: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import prepare_data_with_valid as dataset\n",
    "X_train = dataset.X_train_input\n",
    "y_train = dataset.X_train_target[:,:,:,np.newaxis]\n",
    "X_test = dataset.X_dev_input\n",
    "y_test = dataset.X_dev_target[:,:,:,np.newaxis]\n",
    "\n",
    "\n",
    "if task == 'all':\n",
    "    y_train = (y_train > 0).astype(int)\n",
    "    y_test = (y_test > 0).astype(int)\n",
    "elif task == 'necrotic':\n",
    "    y_train = (y_train == 1).astype(int)\n",
    "    y_test = (y_test == 1).astype(int)\n",
    "elif task == 'edema':\n",
    "    y_train = (y_train == 2).astype(int)\n",
    "    y_test = (y_test == 2).astype(int)\n",
    "elif task == 'enhance':\n",
    "    y_train = (y_train == 4).astype(int)\n",
    "    y_test = (y_test == 4).astype(int)\n",
    "else:\n",
    "    exit(\"Unknow task %s\" % task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DEFINE HYPER-PARAMETERS\n",
    "1. Batch Size: refers to the number of training examples utilized in one iteration\n",
    "2. Learning Rate (lr): learning rate is a hyper-parameter that controls how much we are adjusting the weights of our network with respect the loss gradient.\n",
    "3. Beta1: The exponential decay rate for the 1st moment estimates on Adam Optimizer \n",
    "4. Epoch: refers to the number of iteration to train all the training dataset \n",
    "\n",
    "-----------------------------------------------------------------------------------\n",
    "This network using Adam Optimizer. Adam is an optimization algorithm that can used instead of the classical stochastic gradient descent procedure to update network weights iterative based in training data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "lr = 0.0001 \n",
    "# lr_decay = 0.5\n",
    "# decay_every = 100\n",
    "beta1 = 0.9\n",
    "n_epoch = 5\n",
    "print_freq_step = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### SHOWING THE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "showImage = True\n",
    "\n",
    "# show one slice\n",
    "X = np.asarray(X_train[80])\n",
    "y = np.asarray(y_train[80])\n",
    "# print(X.shape, X.min(), X.max()) # (240, 240, 4) -0.380588 2.62761\n",
    "# print(y.shape, y.min(), y.max()) # (240, 240, 1) 0 1\n",
    "nw, nh, nz = X.shape\n",
    "vis_imgs(X, y, 'samples/{}/_train_im.png'.format(task), showImage)\n",
    "# show data augumentation results\n",
    "for i in range(batch_size):\n",
    "    x_flair, x_t1, x_t1ce, x_t2, label = distort_imgs([X[:,:,0,np.newaxis], X[:,:,1,np.newaxis],\n",
    "            X[:,:,2,np.newaxis], X[:,:,3,np.newaxis], y])#[:,:,np.newaxis]])\n",
    "    # print(x_flair.shape, x_t1.shape, x_t1ce.shape, x_t2.shape, label.shape) # (240, 240, 1) (240, 240, 1) (240, 240, 1) (240, 240, 1) (240, 240, 1)\n",
    "    X_dis = np.concatenate((x_flair, x_t1, x_t1ce, x_t2), axis=2)\n",
    "    # print(X_dis.shape, X_dis.min(), X_dis.max()) # (240, 240, 4) -0.380588233471 2.62376139209\n",
    "    vis_imgs(X_dis, label, 'samples/{}/_train_im_aug{}.png'.format(task, i), showImage)\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True))\n",
    "    with tf.device('/gpu:0'): #<- remove it if you train on CPU or other GPU\n",
    "        ###======================== DEFIINE MODEL =======================###\n",
    "        ## nz is 4 as we input all Flair, T1, T1c and T2.\n",
    "        t_image = tf.placeholder('float32', [batch_size, nw, nh, nz], name='input_image')\n",
    "        ## labels are either 0 or 1\n",
    "        t_seg = tf.placeholder('float32', [batch_size, nw, nh, 1], name='target_segment')\n",
    "        ## train inference\n",
    "        net = model.u_net(t_image, is_train=True, reuse=False, n_out=1)\n",
    "        net.summary()\n",
    "        ## test inference\n",
    "        net_test = model.u_net(t_image, is_train=False, reuse=True, n_out=1)\n",
    "\n",
    "        ###======================== DEFINE LOSS =========================###\n",
    "        ## train losses\n",
    "        out_seg = net.outputs\n",
    "        dice_loss = 1 - tl.cost.dice_coe(out_seg, t_seg, axis=[0,1,2,3])#, 'jaccard', epsilon=1e-5)\n",
    "        iou_loss = tl.cost.iou_coe(out_seg, t_seg, axis=[0,1,2,3])\n",
    "        dice_hard = tl.cost.dice_hard_coe(out_seg, t_seg, axis=[0,1,2,3])\n",
    "        loss = dice_loss\n",
    "\n",
    "        ## test losses\n",
    "        test_out_seg = net_test.outputs\n",
    "        test_dice_loss = 1 - tl.cost.dice_coe(test_out_seg, t_seg, axis=[0,1,2,3])#, 'jaccard', epsilon=1e-5)\n",
    "        test_iou_loss = tl.cost.iou_coe(test_out_seg, t_seg, axis=[0,1,2,3])\n",
    "        test_dice_hard = tl.cost.dice_hard_coe(test_out_seg, t_seg, axis=[0,1,2,3])\n",
    "\n",
    "    ###======================== DEFINE TRAIN OPTS =======================###\n",
    "    t_vars = tl.layers.get_variables_with_name('u_net', True, True)\n",
    "    with tf.device('/gpu:0'):\n",
    "        with tf.variable_scope('learning_rate'):\n",
    "            lr_v = tf.Variable(lr, trainable=False)\n",
    "        train_op = tf.train.AdamOptimizer(lr_v, beta1=beta1).minimize(loss, var_list=t_vars)\n",
    "\n",
    "    ###======================== LOAD MODEL ==============================###\n",
    "    tl.layers.initialize_global_variables(sess)\n",
    "    ## load existing model if possible\n",
    "    tl.files.load_and_assign_npz(sess=sess, name=save_dir+'/u_net_{}.npz'.format(task), network=net)\n",
    "    print(\"start training\")\n",
    "    ###======================== TRAINING ================================###\n",
    "    for epoch in range(0, n_epoch+1):\n",
    "        epoch_time = time.time()\n",
    "        ## update decay learning rate at the beginning of a epoch\n",
    "        # if epoch !=0 and (epoch % decay_every == 0):\n",
    "        #     new_lr_decay = lr_decay ** (epoch // decay_every)\n",
    "        #     sess.run(tf.assign(lr_v, lr * new_lr_decay))\n",
    "        #     log = \" ** new learning rate: %f\" % (lr * new_lr_decay)\n",
    "        #     print(log)\n",
    "        # elif epoch == 0:\n",
    "        #     sess.run(tf.assign(lr_v, lr))\n",
    "        #     log = \" ** init lr: %f  decay_every_epoch: %d, lr_decay: %f\" % (lr, decay_every, lr_decay)\n",
    "        #     print(log)\n",
    "\n",
    "        total_dice, total_iou, total_dice_hard, n_batch = 0, 0, 0, 0\n",
    "        for batch in tl.iterate.minibatches(inputs=X_train, targets=y_train,\n",
    "                                    batch_size=batch_size, shuffle=True):\n",
    "            images, labels = batch\n",
    "            step_time = time.time()\n",
    "            ## data augumentation for a batch of Flair, T1, T1c, T2 images\n",
    "            # and label maps synchronously.\n",
    "            data = tl.prepro.threading_data([_ for _ in zip(images[:,:,:,0, np.newaxis],\n",
    "                    images[:,:,:,1, np.newaxis], images[:,:,:,2, np.newaxis],\n",
    "                    images[:,:,:,3, np.newaxis], labels)],\n",
    "                    fn=distort_imgs) # (10, 5, 240, 240, 1)\n",
    "            b_images = data[:,0:4,:,:,:]  # (10, 4, 240, 240, 1)\n",
    "            b_labels = data[:,4,:,:,:]\n",
    "            b_images = b_images.transpose((0,2,3,1,4))\n",
    "            b_images.shape = (batch_size, nw, nh, nz)\n",
    "\n",
    "            ## update network\n",
    "            _, _dice, _iou, _diceh, out = sess.run([train_op,\n",
    "                    dice_loss, iou_loss, dice_hard, net.outputs],\n",
    "                    {t_image: b_images, t_seg: b_labels})\n",
    "            total_dice += _dice; total_iou += _iou; total_dice_hard += _diceh\n",
    "            n_batch += 1\n",
    "\n",
    "            ## you can show the predition here:\n",
    "            # vis_imgs2(b_images[0], b_labels[0], out[0], \"samples/{}/_tmp.png\".format(task))\n",
    "            # exit()\n",
    "\n",
    "            # if _dice == 1: # DEBUG\n",
    "            #     print(\"DEBUG\")\n",
    "            #     vis_imgs2(b_images[0], b_labels[0], out[0], \"samples/{}/_debug.png\".format(task))\n",
    "\n",
    "            if n_batch % print_freq_step == 0:\n",
    "                print(\"Epoch %d step %d 1-dice: %f hard-dice: %f iou: %f took %fs (2d with distortion)\"\n",
    "                % (epoch, n_batch, _dice, _diceh, _iou, time.time()-step_time))\n",
    "\n",
    "            ## check model fail\n",
    "            if np.isnan(_dice):\n",
    "                exit(\" ** NaN loss found during training, stop training\")\n",
    "            if np.isnan(out).any():\n",
    "                exit(\" ** NaN found in output images during training, stop training\")\n",
    "\n",
    "        print(\" ** Epoch [%d/%d] train 1-dice: %f hard-dice: %f iou: %f took %fs (2d with distortion)\" %\n",
    "                (epoch, n_epoch, total_dice/n_batch, total_dice_hard/n_batch, total_iou/n_batch, time.time()-epoch_time))\n",
    "\n",
    "        ## save a predition of training set\n",
    "        for i in range(batch_size):\n",
    "            if np.max(b_images[i]) > 0:\n",
    "                vis_imgs2(b_images[i], b_labels[i], out[i], \"samples/{}/train_{}.png\".format(task, epoch), showImage)\n",
    "                break\n",
    "            elif i == batch_size-1:\n",
    "                vis_imgs2(b_images[i], b_labels[i], out[i], \"samples/{}/train_{}.png\".format(task, epoch), showImage)\n",
    "\n",
    "        ###======================== EVALUATION ==========================###\n",
    "        total_dice, total_iou, total_dice_hard, n_batch = 0, 0, 0, 0\n",
    "        for batch in tl.iterate.minibatches(inputs=X_test, targets=y_test,\n",
    "                                        batch_size=batch_size, shuffle=True):\n",
    "            b_images, b_labels = batch\n",
    "            _dice, _iou, _diceh, out = sess.run([test_dice_loss,\n",
    "                    test_iou_loss, test_dice_hard, net_test.outputs],\n",
    "                    {t_image: b_images, t_seg: b_labels})\n",
    "            total_dice += _dice; total_iou += _iou; total_dice_hard += _diceh\n",
    "            n_batch += 1\n",
    "\n",
    "        print(\" **\"+\" \"*17+\"test 1-dice: %f hard-dice: %f iou: %f (2d no distortion)\" %\n",
    "                (total_dice/n_batch, total_dice_hard/n_batch, total_iou/n_batch))\n",
    "        print(\" task: {}\".format(task))\n",
    "        ## save a predition of test set\n",
    "        for i in range(batch_size):\n",
    "            if np.max(b_images[i]) > 0:\n",
    "                vis_imgs2(b_images[i], b_labels[i], out[i], \"samples/{}/test_{}.png\".format(task, epoch))\n",
    "                break\n",
    "            elif i == batch_size-1:\n",
    "                vis_imgs2(b_images[i], b_labels[i], out[i], \"samples/{}/test_{}.png\".format(task, epoch))\n",
    "\n",
    "        ###======================== SAVE MODEL ==========================###\n",
    "        tl.files.save_npz(net.all_params, name=save_dir+'/u_net_{}.npz'.format(task), sess=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
